{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Number Evaluation Metric\n",
    "\n",
    "When we are tuning hyperparameters or trying different things to improve the model, it would be much efficient and faster if we have a single real number evaluation metric that lets you quickly tell if the new thing you just tried is working better than the previous last.\n",
    "\n",
    "One way to evaluate the performance of the model is to look at its precision and recall.\n",
    "\n",
    "- Precision: Out of all the examples, how many are of the label that we want? In other words, what is the percentage of the label that we want in the whole dataset?\n",
    "\n",
    "\n",
    "- Recall: What is the percentage that if a new input is given to our model, it will predict it correctly? \n",
    "\n",
    "There is often a tradeoff between Precision and Recall. In Machine Learing, we care about both, so we will use something called **Harmonic Mean** (in Mathematics), or **F1 Score** (in Machine learning). \n",
    "$$ \\text{F}1 = \\frac{ 2 }{  \\frac{1}{P} + \\frac{1}{R}  }  $$\n",
    "where P and R are Precision and Recall respectively.\n",
    "\n",
    "The better the $F1$ Score, the better the model !!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Satisficing and Optimizing Metrics\n",
    "\n",
    "There could be some cases where we aren't able to use a single row number evaluation metric. In those cases, we can set up \"satisficing and optimization metrics\".\n",
    "\n",
    "Let us say that we have two metrics, Accuracy of the model and the Running Time of the model. We cannot set up a single value metric for evaluation. In this case, we can do the following method to select the model: Use **Accuracy** as the **Optimizing** metric and **Running Time** as the **Satisficing** metric. That means select a value that the model needs to satisfy for Running time, and choose the max accuracy of model from those filtered running times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Dev/Test Distributions\n",
    "\n",
    "One thing to keep in mind is that the Dev/Test data should have same distributions, which is the distribution of all the data mixed together. \n",
    "\n",
    "So, we can choose a dev set and test set to reflect data you expect to get in the future and consider important to do well on."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2f9be63dc4f67cd23638b8e785a0e27a8af8598712c0c689e320ac3cb92769c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
